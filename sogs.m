% Second-order gradient sampling method (SOGS) for nonsmooth optimization
%   An implementation of Algorithm 4.3 from [1] for the minimization of
%   nonsmooth, nonconvex optimization problems based on sampling
%   second-order information of the objective function.  
%       
% Input:
%   problem_data is a struct with the following fields:
%       n: Number of variables.
%       x0: Initial point (as a column vector).
%       f: Function handle that returns the objective function at a
%           given point.
%       subgrad_f: Function handle that returns an arbitrary element
%           of the subdifferential at a given point.
%       subhess_f: Function handle that returns a matrix for the
%           second-order 0-jet at a given point. (Typically the
%           Hessian matrix at that point.)
% 
%   algo_options is a struct with the followings fields:
%       eps_arr: Array of radii for the eps-jet. (Should be decreasing.)
%       tau_arr: Array of tolerances for sufficient decrease. (Should be
%           decreasing.) 
%       c: Approximation parameter for the eps-jet (in (0,1)).
%       sp_solver: The solver that is used for solving the subproblems.
%           Either 'fmincon' or 'IPOPT' (from [2]). In our experience,
%           IPOPT is almost always significantly faster. For a large
%           speedup in IPOPT, remove the version check in line 251 in
%           ipopt.m by setting  
%               isOctave = false;
%       sp_solver_options: Options for the subproblem solver. For fmincon,
%           this must be an options object, e.g., created via optimoptions.
%           For IPOPT this must be a struct with the field 'tol' for
%           setting the convergence tolerance (see IPOPT documentation).
%       init_N_sample: Number of randomly sampled points from the eps-ball
%           for the initialization of W in Step 1 of Algo. 4.2. The first
%           point is always the midpoint of the eps-ball. Setting this to 1
%           means that no points are randomly sampled and the algorithm is
%           fully deterministic. (This is always the case in [1].)
%       memory_max_size: Maximum number of jet elements that are stored for
%           warm-starting Algo. 4.2. (Similar to the bundle in
%           bundle-methods.) If the memory is full and a new element is to
%           be added, the oldest element is removed. Note that for every
%           call of Algo. 4.2, only elements that were sampled at points
%           from the current eps-ball are actually reused.
%           IMPORTANT: This is not an upper bound for the number of points
%           that are sampled via Algo 4.2. (This must be unbounded to
%           assure convergence.)
%       max_iter: Maximum number of iterations of the inner loop, i.e., for
%           fixed eps_arr(j) and tau_arr(j). The total number of
%           iterations of the algorithm is max_iter*numel(eps_arr).
%       disp_flag: Flag for the amount of output in the command window
%           during execution:
%               0: No output (except for important warnings).
%               1: Final objective value, runtime and number of evaluations
%               are displayed after execution.
%               2: Detailed information of every inner iteration is
%               displayed. This includes computation of the element with
%               the smallest norm in the current eps-subdiff.
%               approximation. This is done via quadprog, which slightly
%               slows down the algorithm. As such, this flag should not be
%               chosen when runtime is important!
%
% Output:
%   x_opt: Final iterate.
%   f_opt: Objective value at the final iterate.
%   x_cell: Cell array containing all iterates generated by the algorithm.
%       x_cell{j} contains the iterates generated in the inner loop for
%       (eps_arr(j),tau_arr(j)). (So x_cell{j}(:,end) = x_cell{j+1}(:,1).) 
%   eval_counter: Struct containing the number of oracle calls with fields 
%       f_eval: f evaluations.
%       subgrad_eval: Subgradient evaluations.
%       subhess_eval: Hessian evaluations.
%   numsample_cell: Cell array containing the number of sample points
%       required for each inner iteration.
%   mu_cell: Cell array containing the Lagrange multiplier corresponding
%       the the eps-ball constraint in the (final) subproblem for each
%       inner iteration. 
%
% [1] Gebken, "Using second-order information in gradient sampling methods
% for nonsmooth optimization" (2025) 
% [2] Enrico Bertolazzi (2024). ebertolazzi/mexIPOPT
% (https://github.com/ebertolazzi/mexIPOPT/releases/tag/1.1.6), GitHub.

function [x_opt,f_opt,x_cell,eval_counter,numsample_cell,mu_cell] = sogs(problem_data,algo_options)

% Read inputs
n = problem_data.n;
x0 = problem_data.x0;
f = problem_data.f;
subgrad_f = problem_data.subgrad_f;
subhess_f = problem_data.subhess_f;

eps_arr = algo_options.eps_arr;
tau_arr = algo_options.tau_arr;
c = algo_options.c;
sp_solver = algo_options.sp_solver;
sp_solver_options = algo_options.sp_solver_options;
init_N_sample = algo_options.init_N_sample;
memory_max_size = algo_options.memory_max_size;
max_iter = algo_options.max_iter;
disp_flag = algo_options.disp_flag;

% Tic for measuring runtime
if(disp_flag >= 1)
    start_tic = tic;
end

% Initialize the evaluation counters
eval_counter.f_eval = 0;
eval_counter.subgrad_eval = 0;
eval_counter.subhess_eval = 0;

% Initialize the memory
memory.sample_pts = [];
memory.f_vals = [];
memory.subgrads = [];
memory.subhess = {};
memory.max_size = memory_max_size;

% Initialize cell arrays
j_max = numel(eps_arr);
x_cell = cell(1,j_max);
numsample_cell = cell(1,j_max);
mu_cell = cell(1,j_max);

% Outer loop
for j = 1:j_max
    if(disp_flag >= 2)
        disp(['----- Outer iteration j = ',num2str(j),' -------------------']);
        disp(['    eps_j = ',num2str(eps_arr(j)),', tau_j = ',num2str(tau_arr(j))]);
    end

    % Initialize arrays for inner loop
    if(j == 1)
        %%%%%%%%%%%%%%%%%%
        %%%%% Step 1 %%%%%
        %%%%%%%%%%%%%%%%%%
        x_arr = [x0,NaN(n,max_iter-1)];
        f_x = f(x0); eval_counter.f_eval = eval_counter.f_eval + 1;
    else
        x_arr = [x_cell{j-1}(:,end),NaN(n,max_iter)];
    end
    numsample_arr = NaN(1,max_iter);
    mu_arr = NaN(1,max_iter);

    % Inner loop
    for i = 1:max_iter
        
        if(disp_flag >= 2)
            disp(['    ----- Inner iteration j = ',num2str(j),', i = ',num2str(i),') -----']);
            disp(['        eps_j = ',num2str(eps_arr(j)),', tau_j = ',num2str(tau_arr(j))]);
        end

        %%%%%%%%%%%%%%%%%%
        %%%%% Step 2 %%%%%
        %%%%%%%%%%%%%%%%%%
        
        % Call Algo. 4.2 for approximating the eps-jet and solving the
        % subproblem
        %%%%%%%%%%%%%%%%%%%%%%%%%%
        %%%% Alg. 4.2, Step 1 %%%%
        %%%%%%%%%%%%%%%%%%%%%%%%%%

        % Reuse memorized elements
        if(size(memory.sample_pts,2) > 0)
            inds = vecnorm(memory.sample_pts - x_arr(:,i),2,1) <= eps_arr(j) + 10^-14;

            W_sample_pts = memory.sample_pts(:,inds);
            W_f_vals = memory.f_vals(inds);
            W_subgrads = memory.subgrads(:,inds);
            W_subhess = memory.subhess(inds);

            N_reused = size(W_sample_pts,2);

            if(disp_flag >= 2)
                disp(['        Reusing ',num2str(N_reused),' sample points. (Memory size = ',num2str(size(memory.sample_pts,2)),'.)'])
            end
        else
            W_sample_pts = [];
            W_f_vals = [];
            W_subgrads = [];
            W_subhess = {};

            N_reused = 0;
        end

        % Sample new elements of the eps-jet
        if(disp_flag >= 2)
            disp(['        Initially sampling ',num2str(init_N_sample),' point(s).'])
        end
        W_sample_pts(:,end+1:end+init_N_sample) = x_arr(:,i) + eps_arr(j)*sample_hypersphere(n,init_N_sample);
        W_f_vals(end+1:end+init_N_sample) = NaN(1,init_N_sample);
        W_subgrads(:,end+1:end+init_N_sample) = NaN(n,init_N_sample);
        W_subhess(end+1:end+init_N_sample) = cell(1,init_N_sample);

        for k = 1:init_N_sample
            if(k == 1)
                W_f_vals(N_reused + 1) = f_x; % First point is the center of the eps-ball
            else
                W_f_vals(N_reused + k) = f(W_sample_pts(:,N_reused + k)); eval_counter.f_eval = eval_counter.f_eval + 1;
            end
            W_subgrads(:,N_reused + k) = subgrad_f(W_sample_pts(:,N_reused + k)); eval_counter.subgrad_eval = eval_counter.subgrad_eval + 1;
            W_subhess{N_reused + k} = subhess_f(W_sample_pts(:,N_reused + k)); eval_counter.subhess_eval = eval_counter.subhess_eval + 1;
        end
        N_W = N_reused + init_N_sample;


        while(1)
            %%%%%%%%%%%%%%%%%%%%%%%%%%
            %%%% Alg. 4.2, Step 2 %%%%
            %%%%%%%%%%%%%%%%%%%%%%%%%%

            if(strcmp(sp_solver,'fmincon'))
                [z,theta,lag_mult] = solve_subproblem_fmincon(W_sample_pts,W_f_vals,W_subgrads,W_subhess,x_arr(:,i),eps_arr(j),sp_solver_options);
            else
                [z,theta,lag_mult] = solve_subproblem_IPOPT(W_sample_pts,W_f_vals,W_subgrads,W_subhess,x_arr(:,i),eps_arr(j),sp_solver_options);
            end
            f_z = f(z); eval_counter.f_eval = eval_counter.f_eval + 1;

            %%%%%%%%%%%%%%%%%%%%%%%%%%
            %%%% Alg. 4.2, Step 3 %%%%
            %%%%%%%%%%%%%%%%%%%%%%%%%%

            if(theta - f_x > -tau_arr(j)*eps_arr(j))
                reduction_flag = true;
                break
            elseif(f_z <= c*theta + (1 - c)*f_x)
                reduction_flag = false;
                break
            end

            %%%%%%%%%%%%%%%%%%%%%%%%%%
            %%%% Alg. 4.2, Step 6 %%%%
            %%%%%%%%%%%%%%%%%%%%%%%%%%

            N_W = N_W + 1;
            W_sample_pts(:,end+1) = z;
            W_f_vals(end+1) = f_z;
            W_subgrads(:,end+1) = subgrad_f(z); eval_counter.subgrad_eval = eval_counter.subgrad_eval + 1;
            W_subhess{end+1} = subhess_f(z); eval_counter.subhess_eval = eval_counter.subhess_eval + 1;
        end

        % Store newly sampled jet elements
        if(memory.max_size > 0)
            memory = add_to_memory(W_sample_pts(:,N_reused + 1 : end),...
                W_f_vals(N_reused + 1 : end),...
                W_subgrads(:,N_reused + 1 : end),...
                W_subhess(:,N_reused + 1 : end),...
                memory);
        end
        
        % Save number of sample points and Lagrange multiplier
        numsample_arr(i) = N_W - N_reused;
        mu_arr(i) = lag_mult.ineqnonlin(end);

        if(disp_flag >= 2)
            disp(['        ',num2str(N_W - init_N_sample - N_reused),' additional sample points required. ',...
                '(Nonzero (>10^-4) multipliers = ',num2str(sum(lag_mult.ineqnonlin(1:end-1) > 10^-4)),...
                '. mu = ',num2str(lag_mult.ineqnonlin(end)),').']);
            disp(['        f(x^{j,i}) = ',sprintf('%9.2e', f_x)]);
            disp(['        f(z)       = ',sprintf('%9.2e', f_z)]);
            disp(['        theta      = ',sprintf('%9.2e', theta)]);
            disp(['        f(x^{j,i}) - f(z) = ',sprintf('%9.2e', f_x - f_z)]);
            disp(['        min(f(W_sample_pts)) = ',sprintf('%9.2e', min(W_f_vals))]);

            disp(['        Approx. opt. measure 0 = ',sprintf('%9.2e', min(vecnorm(W_subgrads,2,1)))]);
            disp(['        Approx. opt. measure 1 = ',sprintf('%9.2e', norm(W_subgrads*lag_mult.ineqnonlin(1:end-1)/sum(lag_mult.ineqnonlin(1:end-1)),2))]);
            [~,fval] = quadprog(2*(W_subgrads'*W_subgrads),zeros(N_W,1),[],[],ones(1,N_W),1,zeros(N_W,1),ones(N_W,1),[],optimoptions('quadprog','Display','off'));
            om = sqrt(fval);
            disp(['        Approx. opt. measure 2 = ',sprintf('%9.2e', om)])
            disp(' ');
        end

        if(reduction_flag)
            %%%%%%%%%%%%%%%%%%
            %%%%% Step 4 %%%%%
            %%%%%%%%%%%%%%%%%%
            
            if(disp_flag >= 2)
                disp('        Decision: Stopping criterion satisfied')
                disp(['        (theta - f(x^{j,i}))/eps_j = ',sprintf('%9.2e', (theta - f_x)/eps_arr(j))]);
                disp(['        tau_j                      = ',sprintf('%9.2e', tau_arr(j))]);
                disp(' ');
            end

            x_arr = x_arr(:,1:i);
            numsample_arr = numsample_arr(1:i);
            mu_arr = mu_arr(1:i);
            break
        else
            %%%%%%%%%%%%%%%%%%
            %%%%% Step 6 %%%%%
            %%%%%%%%%%%%%%%%%%

            if(disp_flag >= 2)
                disp('        Decision: Point accepted')
                disp(['        (theta - f(x^{j,i}))/eps_j = ',sprintf('%9.2e', (theta - f_x)/eps_arr(j))]);
                disp(['        tau_j                      = ',sprintf('%9.2e', tau_arr(j))]);
                disp(['        ||z - x^{j,i}|| = ',sprintf('%9.2e', norm(z - x_arr(:,i),2))]);
                disp(['        eps_j           = ',sprintf('%9.2e', eps_arr(j))]);
                disp(' ');
            end

            x_arr(:,i+1) = z;
            f_x = f_z;
        end
    end

    % Save information of inner iteration to cell arrays
    x_cell{j} = x_arr;
    numsample_cell{j} = numsample_arr;
    mu_cell{j} = mu_arr; 

    if(i == max_iter && ~reduction_flag)
        fprintf(2,'Warning: Maximal number of iterations reached before stopping criterion is satisfied.\n')
    end
end

% Prepare output
x_opt = x_cell{j_max}(:,end);
f_opt = f_x;

if(disp_flag >= 1)
    disp('Algorithm finished!');
    disp(['    Final objective value =',sprintf('%9.2e', f_opt)]);
    disp(['    Runtime               = ',num2str(toc(start_tic)),'s']);
    disp('    Required evaluations: ');
    disp(['        f       - ',num2str(eval_counter.f_eval)])
    disp(['        subgrad - ',num2str(eval_counter.subgrad_eval)])
    disp(['        subhess - ',num2str(eval_counter.subhess_eval)])
end

end

